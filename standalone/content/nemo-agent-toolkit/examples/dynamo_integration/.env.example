# SPDX-FileCopyrightText: Copyright (c) 2025-2026, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

export HF_HOME=/path/to/local/storage/.cache/huggingface

export HF_TOKEN=my_huggingface_read_token

# Required: Set your model directory path with model weights
# EXAMPLE ls from properly configured directory
# ~/models/Llama-3.3-70B-Instruct$ ls
# LICENSE                           model-00003-of-00030.safetensors  model-00010-of-00030.safetensors  model-00017-of-00030.safetensors  model-00024-of-00030.safetensors  model.safetensors.index.json
# README.md                         model-00004-of-00030.safetensors  model-00011-of-00030.safetensors  model-00018-of-00030.safetensors  model-00025-of-00030.safetensors  original
# USE_POLICY.md                     model-00005-of-00030.safetensors  model-00012-of-00030.safetensors  model-00019-of-00030.safetensors  model-00026-of-00030.safetensors  special_tokens_map.json
# config.json                       model-00006-of-00030.safetensors  model-00013-of-00030.safetensors  model-00020-of-00030.safetensors  model-00027-of-00030.safetensors  tokenizer.json
# generation_config.json            model-00007-of-00030.safetensors  model-00014-of-00030.safetensors  model-00021-of-00030.safetensors  model-00028-of-00030.safetensors  tokenizer_config.json
# model-00001-of-00030.safetensors  model-00008-of-00030.safetensors  model-00015-of-00030.safetensors  model-00022-of-00030.safetensors  model-00029-of-00030.safetensors
# model-00002-of-00030.safetensors  model-00009-of-00030.safetensors  model-00016-of-00030.safetensors  model-00023-of-00030.safetensors  model-00030-of-00030.safetensors
export DYNAMO_MODEL_DIR=/path/to/your/models/Llama-3.3-70B-Instruct

# Set repository directory (for Thompson Sampling router)
export DYNAMO_REPO_DIR=/path/to/NeMo-Agent-Toolkit/external/dynamo

# =============================================================================
# OPTIONAL VARIABLES - GPU Configuration
# =============================================================================

# GPU device IDs for unified mode (comma-separated)
# Default: 0,1,2,3
export DYNAMO_GPU_DEVICES=0,1,2,3

# GPU device IDs for disaggregated mode prefill workers
# Default: 0,1
# DYNAMO_PREFILL_GPUS=0,1

# GPU device IDs for disaggregated mode decode workers
# Default: 2,3
# DYNAMO_DECODE_GPUS=2,3

# Tensor parallelism size (number of GPUs per worker)
# Default: 4 for unified mode, 2 for disaggregated mode
# DYNAMO_TP_SIZE=4

# =============================================================================
# OPTIONAL VARIABLES - Network Configuration
# =============================================================================

# HTTP port for Dynamo frontend API
# Default: 8099
# DYNAMO_HTTP_PORT=8099

# ETCD client port for metadata and discovery
# Default: 2379
# DYNAMO_ETCD_PORT=2379

# ETCD peer port
# Default: 2390
# DYNAMO_ETCD_PEER_PORT=2390

# NATS messaging port
# Default: 4222
# DYNAMO_NATS_PORT=4222

# =============================================================================
# OPTIONAL VARIABLES - Model Configuration
# =============================================================================

# Model name as exposed by the API
# Default: llama-3.3-70b
# DYNAMO_MODEL_NAME=llama-3.3-70b

# Shared memory size for Docker container
# Default: 16g
# DYNAMO_SHM_SIZE=16g

# =============================================================================
# OPTIONAL VARIABLES - Disaggregated Mode
# =============================================================================

# Bootstrap port for disaggregated mode communication
# Default: 12345
# DYNAMO_DISAGG_BOOTSTRAP_PORT=12345

# Transfer backend for KV cache (nixl, nccl, or gloo)
# Default: nixl
# DYNAMO_DISAGG_TRANSFER_BACKEND=nixl

# =============================================================================
# OPTIONAL VARIABLES - Performance Tuning
# =============================================================================

# Worker initialization timeout (seconds)
# Increase for large models (70B+) or cold starts
# Default: 1800 (30 minutes)
# DYNAMO_WORKER_INIT_TIMEOUT_S=1800
